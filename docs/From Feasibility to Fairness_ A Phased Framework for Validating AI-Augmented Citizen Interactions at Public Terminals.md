# From Feasibility to Fairness: A Phased Framework for Validating AI-Augmented Citizen Interactions at Public Terminals

## Phase 1: Technical Feasibility Validation

The initial phase of this research program is dedicated to validating the foundational technical viability of the proposed AI-augmented interaction paradigm. The central hypothesis posits that a successful implementation hinges on a robust, low-latency communication channel between a public terminal and a user's personal AI companion, coupled with seamless interoperability across a heterogeneous landscape of hardware and software. This phase directly addresses the critical questions of timing, reliability, and compatibility, which form the bedrock upon which user experience and policy can be built. Failure to establish feasibility here would render subsequent phases moot. The validation process focuses on three core pillars: measuring end-to-end round-trip latency under varied network conditions; assessing the cross-vendor interoperability of a standardized plugin grammar; and profiling the on-device resource consumption of adaptive AI functions.

The first pillar of feasibility is the measurement of end-to-end latency for the core transactional loop: `Terminal → AI Companion → Wallet / Guard → Terminal`. This round-trip time is not merely a performance metric but a critical determinant of user perception and safety, particularly in high-stakes environments like fuel pumps . For a driver authorizing payment at a pump, a noticeable delay could lead to frustration or even physical obstruction of the pump island . Similarly, at a busy retail counter, slow response times would degrade throughput and customer satisfaction. The research plan mandates measuring this latency across all target terminal types—fuel pumps, pin-pads, and kiosks—to capture environment-specific bottlenecks . Crucially, testing must extend beyond ideal lab conditions to simulate "degraded networks," as poor cellular reception at remote locations or during peak hours is a common real-world scenario [[5](https://www.linkedin.com/posts/skdash_innovationleadership-samsungpay-digitalpayments-activity-7384453814885535744-0W4g)]. The analysis reveals that achieving acceptable latency necessitates a hybrid computational architecture. While some processing can occur in the cloud, Edge AI offers significant advantages by enabling real-time decision-making without the delays inherent in cloud round trips [[26](https://gettobyte.com/edge-ai-technology/?srsltid=AfmBOoqJuqf5JOWzlR4WLVjNynU60yRSiBzyygxaQediTOTXoqnSVMhi), [27](https://www.mdpi.com/2673-4052/6/3/37)]. This local processing also enhances privacy by keeping sensitive data on the user's device [[26](https://gettobyte.com/edge-ai-technology/?srsltid=AfmBOoqJuqf5JOWzlR4WLVjNynU60yRSiBzyygxaQediTOTXoqnSVMhi)]. Techniques from the TinyML community, which focus on deploying efficient deep learning models on microcontrollers with constrained resources, are directly applicable here [[17](https://www.mdpi.com/2072-666X/13/6/851), [18](https://www.arm.com/campaigns/arm-tinyml), [45](https://www.researchgate.net/publication/390144326_Optimising_TinyML_with_quantization_and_distillation_of_transformer_and_mamba_models_for_indoor_localisation_on_edge_devices), [46](https://www.researchgate.net/publication/390897061_Efficient_TinyML_Architectures_for_On-Device_Small_Language_Models_Privacy-Preserving_Inference_at_the_Edge)]. By leveraging TinyML, the AI companion could perform lightweight corridor checks locally, reserving more computationally intensive tasks for cloud-based inference when necessary. The primary missing data point is the real distribution of latency and failure modes observed in Phoenix-style pilot programs, which cannot be fully replicated through lab simulations alone .

The second pillar is ensuring interoperability across different POS systems. The ambitious goal is to create a single, universal `BfcPosPlugin` and DID handshake grammar that works seamlessly with disparate vendors such as Verifone, Clover, and SoftPOS applications . This ambition is driven by the need for scalability and avoiding vendor lock-in. However, achieving this requires acknowledging the reality of proprietary systems. The most practical path to universal compatibility involves a two-layer architectural strategy. First, a set of shared primitives must be defined. These include a standardized vocabulary of events (`StartSession`, `SelectService`, `AuthorizePayment`, `NetworkDegraded`) and a consistent set of `ConsentReason` codes (`rights violation`, `essential unstable`, etc.) . This creates a common language that any compliant AI companion can understand. Second, and more critically, a "normalization layer" or per-vendor adapter is required . This adapter acts as a translator, converting a specific vendor's proprietary event codes, message formats, and error messages into the shared primitives before they are processed by the AI companion's logic engine. The most significant engineering challenge and the primary source of missing data lie in cataloging the specific quirks of each vendor. This includes undocumented behaviors, strict message size limits, unique interpretations of error codes, and variations in how they handle asynchronous events . For instance, MasterCard's testing and certification processes involve real production-grade EMV terminals, including various POS devices and SoftPOS Android terminals, highlighting the diversity that must be accommodated [[43](https://eazypaytech.com/mastercard-testing-and-certification/)]. Understanding these differences is paramount for building a resilient system that can function reliably in the wild.

The third pillar concerns the on-device resource constraints of the AI companion itself. The proposed features, such as real-time corridor checks and dynamic prompt rewriting, are computationally demanding . It is essential to profile the CPU, memory, and battery costs associated with these functions to establish realistic boundaries for what the system can offer. The concept of an "organicCPU" provides a useful conceptual model for understanding cognitive load, but translating this metaphor into measurable device telemetry is a key research task . This involves developing reliable proxies for cognitive strain, such as spikes in CPU usage, increased memory allocation, or rapid battery drain, which can serve as signals for the system to throttle its own complexity. A crucial aspect of this research will be to conduct a cost-benefit analysis, determining the point of diminishing returns for any given adaptation. For example, does reducing the prompt rate from three to two per minute justify the additional energy consumption? The answer likely varies significantly depending on the user's profile; a neurodivergent user might derive substantial benefit from such a reduction, whereas a typical user may not notice or care. This underscores the need for dynamic adaptation, where the system weighs the cost of an adaptation against the perceived state of the user's cognitive corridors. Resource profiling must be conducted across a range of potential companion devices, from powerful smartphones to simpler headsets or embedded edge boxes located at kiosks or pumps . Legacy hardware, such as the Verifone VX820, which has only 160 MB of RAM, represents a hard constraint on what can be run on-device, reinforcing the need for a minimalist projection of user data on public terminals [[15](https://www.alibaba.com/product-detail/Verifone-VX820-POS-machine-and-spare_1600977898125.html), [82](https://www.ebay.com/itm/156675094591)]. The experiment design for measuring LLM inference power consumption on a Raspberry Pi 4 (4GB) serves as a relevant methodology for conducting such resource profiling on representative edge devices [[16](https://arxiv.org/html/2504.03360v1)].

| Feasibility Validation Metric | Target Environments | Key Data to Collect | Relevant Technologies/Concepts |
| :--- | :--- | :--- | :--- |
| **End-to-End Round-Trip Latency** | Fuel Pumps, Pin-Pads, Kiosks | Time from terminal prompt to AI decision to POS authorization. Success/failure rates under normal and degraded network conditions.  | Edge AI, TinyML, Low-Latency Networks, Real-Time Decision-Making [[16](https://arxiv.org/html/2504.03360v1), [26](https://gettobyte.com/edge-ai-technology/?srsltid=AfmBOoqJuqf5JOWzlR4WLVjNynU60yRSiBzyygxaQediTOTXoqnSVMhi), [27](https://www.mdpi.com/2673-4052/6/3/37)] |
| **Cross-Vendor Interoperability** | Verifone, Clover, SoftPOS | Per-vendor field quirk mappings, message size limits, error-code semantics, custom mapping effort required. Differences in behavior and UX.  | W3C DIDs, Verifiable Credentials (VC), Normalization Layer, API Framework [[10](https://arxiv.org/html/2509.05797v1), [84](https://www.linkedin.com/pulse/building-softpos-mpos-android-programming-hani-fahmi-b26me), [91](https://arxiv.org/pdf/2601.14982), [92](https://www.mdpi.com/1424-8220/22/15/5641)] |
| **On-Device Resource Usage** | Owned Devices (Phone/Headset), Public Terminals (Edge Box) | CPU cycles, memory allocation, battery drain during real-time corridor checks and prompt rewriting. OrganicCPU-like load bands.  | Model Quantization, Distillation, Hardware-Aware Optimization, Energy-Aware Deep Learning [[28](https://link.springer.com/article/10.1007/s11554-025-01703-0), [45](https://www.researchgate.net/publication/390144326_Optimising_TinyML_with_quantization_and_distillation_of_transformer_and_mamba_models_for_indoor_localisation_on_edge_devices), [46](https://www.researchgate.net/publication/390897061_Efficient_TinyML_Architectures_for_On-Device_Small_Language_Models_Privacy-Preserving_Inference_at_the_Edge)] |

In summary, Phase 1 is a rigorous technical audit designed to stress-test the core assumptions of the entire system. By methodically measuring latency, documenting interoperability challenges, and profiling resource usage, this phase will provide the indispensable data needed to determine if the envisioned AI-mediated interaction layer is a practical reality. The findings will dictate the scope of the UX studies in Phase 2 and the granularity of the policy rules in Phase 3, ensuring that all subsequent development is grounded in solid technical evidence rather than theoretical possibilities.

## Phase 2: User Experience and Human Impact Assessment

Building upon the validated technical foundation from Phase 1, Phase 2 shifts the focus squarely to the human element: evaluating whether the AI-augmented interactions actually improve the user experience for augmented citizens. This phase moves beyond abstract feasibility to measure tangible outcomes related to cognitive load, task completion, and trust. The central research question is not just "Can it work?" but "Does it help people?" Controlled studies comparing the new AI-assisted flows against traditional methods (like card-and-PIN or direct-to-clerk interactions) will be essential to quantify the system's impact. This phase is predicated on the insight that true accessibility is achieved not through static accommodations but through dynamic, context-aware adaptation that responds to a user's real-time needs . To do this effectively, the research must employ a multi-modal assessment framework combining objective behavioral data with subjective user feedback.

A primary concern for many users, especially those with neurodivergent conditions or cognitive impairments, is excessive cognitive load [[51](https://www.sciencedirect.com/science/chapter/edited-volume/pii/B9780128128008000096)]. The research plan wisely identifies several objective metrics to track this load, including prompts per minute, steps per task, errors made, and points of task abandonment . However, to gain a deeper understanding of the user's mental state, these objective logs must be complemented by established psychological assessment tools. The NASA Task Load Index (NASA-TLX) is a well-validated, subjective workload rating scale that has been widely used in human factors research to assess mental, physical, and temporal demands [[40](https://www.researchgate.net/publication/321758558_Effects_of_button_design_characteristics_on_performance_and_perceptions_of_touchscreen_use), [57](https://www.scribd.com/document/909450430/Peripheral-Interaction-Challenges-and-Opportunities-for-HCI-in-the-Periphery-of-Attention-by-Saskia-Bakker-Doris-Hausen-Ted-Selker-Eds-Z-lib-org)]. Incorporating this tool alongside the objective logs will allow researchers to triangulate their findings, correlating raw data (e.g., high error rates) with the user's self-reported sense of strain. A significant gap in the available information is the lack of baseline cognitive-load benchmarks for typical interactions at gas stations, kiosks, and ATMs, particularly for comparisons between drivers and non-drivers, and between augmented and non-augmented users . Establishing these baselines is a critical first step in the controlled studies, as it provides a reference point against which the effectiveness of the AI assistance can be measured. The ultimate innovation lies in testing the efficacy of dynamic, real-time adaptation based on "organicCPU/corridor" telemetry . This approach, analogous to digital phenotyping used in mental health chatbots [[3](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA), [4](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)], uses real-time data from the interaction (error counts, hesitation times, physiological proxies) to nudge the interface toward being less complex—fewer prompts, more batching, simpler language—when cognitive overload is detected. The research must empirically test whether this optimization layer improves outcomes over and above the benefits provided by fixed accessibility profiles (low-vision, motor-limited, etc.). Key unanswered questions include how quickly the system can adapt without causing confusion and which corridor signals are robust enough for use in uncontrolled, public environments .

The ultimate measures of success are task completion rates and the establishment of user trust. The study design must feature a clear comparative analysis, pitting classic flows against multiple AI-assisted scenarios: the AI companion handling the interaction entirely, a kiosk using "personalization tokens" to auto-configure itself, and a hybrid model where the AI companion assists both the user and the clerk . This will reveal not only if the AI helps but also *how much* it helps relative to existing methods. A major missing piece of data is the fine-grained log of where augmented citizens currently fail in today's systems—for example, at PIN entry, navigating complex menus, or undergoing ID validation, ideally annotated with their specific accessibility and augmentation status . Such data would pinpoint the most painful pain points that the new system is designed to solve. Beyond mere completion, the quality of the interaction matters profoundly. Trust is a multifaceted construct, encompassing feelings of control, clarity, and freedom from stigma . The research plan to collect subjective ratings on these dimensions is crucial. The connection to mental health chatbots provides a valuable parallel; studies have shown that generative AI companions like Therabot can build a high therapeutic alliance with users, comparable to norms seen in outpatient settings [[3](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA), [4](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)]. This suggests that a well-designed AI companion could foster a similar sense of partnership and rapport in a mundane context like paying for fuel. Conversely, there is a significant risk of introducing stigmatizing language or actions that make the user feel blamed or abnormal. The research must carefully investigate how the AI's interventions are perceived. For example, does a system that automatically rewrites a confusing prompt because it detects high cognitive load feel helpful or infantilizing? This distinction is critical for the long-term adoption and acceptance of the technology.

| UX Evaluation Metric | Measurement Method | Key Questions to Answer | Supporting Concepts/Theories |
| :--- | :--- | :--- | :--- |
| **Cognitive Load** | Objective Logs (prompts/min, steps/task) + Subjective Ratings (NASA-TLX) [[40](https://www.researchgate.net/publication/321758558_Effects_of_button_design_characteristics_on_performance_and_perceptions_of_touchscreen_use), [57](https://www.scribd.com/document/909450430/Peripheral-Interaction-Challenges-and-Opportunities-for-HCI-in-the-Periphery-of-Attention-by-Saskia-Bakker-Doris-Hausen-Ted-Selker-Eds-Z-lib-org)] | Does the AI flow reduce cognitive load compared to baseline? How quickly can adaptation be applied without causing confusion?  | Cognitive Theory of Multimedia Learning [[33](https://www.sciencedirect.com/science/article/pii/S2405844024013926)], Mental Workload Reduction [[51](https://www.sciencedirect.com/science/chapter/edited-volume/pii/B9780128128008000096)] |
| **Task Abandonment & Drop-off Points** | Event Logging during controlled studies  | At what specific step or prompt do users give up? Does the AI companion prevent abandonment at these critical junctures? | Human-Computer Interaction (HCI) [[41](https://www.academia.edu/2156159/HUMAN_ERROR_IDENTIFICATION_IN_HUMAN_COMPUTER_INTERACTION)], Usability Engineering [[39](https://pmc.ncbi.nlm.nih.gov/articles/PMC10852311/)] |
| **Task Completion Rate & Recovery** | Comparative Analysis of AI-Assisted vs. Classic Flows  | What is the absolute completion rate for each flow? How often can users recover from errors independently with AI assistance? | Adaptive Systems [[1](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)], Assistive Technology Effectiveness |
| **Trust, Control, and Stigma** | Post-interaction Surveys with Likert-scale questions  | Do users feel more in control with the AI companion? Is the interaction perceived as clear and respectful? Does it evoke stigma? | Human-AI Collaboration [[30](https://arxiv.org/pdf/2301.06937)], Therapeutic Alliance in AI [[3](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA), [4](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)], Stigma Reduction in HCI |

In conclusion, Phase 2 is the heart of the research program, tasked with answering the most important question: does this technology genuinely improve lives? By employing a rigorous, multi-modal assessment strategy that combines quantitative behavioral data with qualitative user feedback, this phase will generate the empirical evidence needed to prove or disprove the value proposition of the AI-augmented interaction layer. The insights gained will be invaluable, not only for refining the system's functionality but also for shaping the ethical guardrails that will define its operation in Phase 3.

## Phase 3: Policy, Consent, and Governance Refinement

With a validated technical architecture and documented positive user experience outcomes, Phase 3 transitions from engineering and design to the realm of law, ethics, and governance. This phase takes the empirical data generated in the previous phases and uses it to refine the policy and consent mechanisms that will govern the AI-augmented interactions. The goal is to move from abstract principles to concrete, enforceable rules that protect user rights while enabling fluid and personalized experiences. This phase addresses three critical areas: formalizing neurorights-based delegation envelopes, empirically tuning the "Word-Math bands" that classify prompts for potential harm, and aligning the `AugmentedCitizenProfile` schema with Self-Sovereign Identity (SSI) ecosystems for portability and control. This work ensures that the system is not only functional and usable but also fair, transparent, and legally compliant.

The first area of focus is the translation of emerging neurorights concepts into actionable technical policies. Neurorights, a nascent legal field focused on protecting mental integrity and privacy, are gaining traction internationally, with Chile being a notable pioneer that amended its constitution to include protections against problematic uses of neuroscience [[6](https://www.linknovate.com/affiliation/columbia-university-210/all/?query=ultimately%20achieving%20unprecedented%20control), [49](https://unesdoc.unesco.org/ark:/48223/pf0000380275_eng), [107](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1330439/full)]. The research must bridge this evolving legal landscape with the technical implementation of the AI companion. The concept of "neurorights envelopes" is a powerful abstraction for managing user permissions . The research must translate jurisdictional laws concerning mental privacy, freedom from manipulation, and cognitive liberty into concrete, machine-readable rules that the AI companion enforces. For example, if a law dictates that no biometric data collected via the interaction can be used for targeted advertising, the AI companion's logic must be programmed to reject any request that violates this principle. Self-Sovereign Identity (SSI) provides a natural and robust framework for managing these delegations [[14](https://www.researchgate.net/publication/373835915_Towards_Interoperable_Self-sovereign_Identities)]. By leveraging W3C standards for Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), the system can create portable, auditable, and cryptographically secure records of user consent [[10](https://arxiv.org/html/2509.05797v1), [11](https://www.linkedin.com/posts/marcellus-nwankwo_w3c-did-verifiablecredentials-activity-7419046038809935872-Z2_T), [96](https://arxiv.org/pdf/2404.06729)]. This approach places the user in control of their identity and data, allowing them to share only the minimal necessary information with a terminal [[106](https://www.enisa.europa.eu/sites/default/files/publications/Digital_Identity_Standards.pdf)]. The research should explore alignment with specific SSI ecosystems, such as the IOTA Identity project, which is built on W3C specifications and designed for interoperability, making it a strong candidate for this application [[11](https://www.linkedin.com/posts/marcellus-nwankwo_w3c-did-verifiablecredentials-activity-7419046038809935872-Z2_T)].

The second area of refinement is the empirical tuning of the "Word-Math bands" (K/E/Y/Z/T/F/O). These bands represent a novel conceptual tool for classifying prompts based on their potential to cause harm, specifically stigma, coercion, or confusion . The effectiveness of this classification system is purely empirical and depends entirely on real-world user feedback. The most critical missing piece of data is the creation of a large, labeled corpus of prompts and interactions . This corpus must be meticulously annotated by both augmented and non-augmented users, who will rate each prompt on dimensions such as perceived stigma, coerciveness, clarity, and overall usefulness. This rich dataset will enable researchers to empirically identify the thresholds at which users report feeling "stuck" or "wrong," and where error and regret rates spike. For example, the data might show that prompts exceeding a certain length or containing specific keywords consistently receive high stigma scores. This allows the system to learn from actual user experience rather than relying on potentially flawed assumptions about what constitutes a "coercive upsell" . This process turns the Word-Math bands from a theoretical framework into a practical, evidence-based policy engine, capable of dynamically adjusting the tone and content of interactions to minimize negative impacts.

The final pillar of this phase is ensuring profile portability and interoperability at the data level. For this system to scale beyond a single vendor or city, a user's accessibility preferences and rights data must be able to travel with them. This requires aligning the custom `AugmentedCitizenProfile` schema with established SSI and VC ecosystems . The research must produce clear mapping tables that define how each field in the custom profile corresponds to a claim within a W3C Verifiable Credential [[12](https://www.w3.org/TR/vc-data-model-2.0/), [101](https://www.w3.org/TR/2023/WD-vc-data-model-2.0-20230307/)]. This ensures that a user's data remains portable and understandable across different platforms and jurisdictions. Furthermore, this process must rigorously identify which claims *must never leave the user's personal device*. This is a fundamental tenet of SSI and a critical security measure, ensuring that highly sensitive personal data remains under the user's sovereign control at all times [[14](https://www.researchgate.net/publication/373835915_Towards_Interoperable_Self-sovereign_Identities)]. The Verifiable Credentials Data Model v2.0 provides the necessary standards for structuring this data securely and privately [[98](https://www.w3.org/standards/history/vc-data-model-2.0/), [100](https://www.linkedin.com/posts/pierregronlier_w3c-verifiable-credentials-20-specifications-activity-7329031162352332800-ZlJy)]. By anchoring the profile schema in these W3C standards, the system can leverage a growing ecosystem of compatible tools and verifiers, fostering a truly open and user-centric platform [[93](https://ieeexplore.ieee.org/iel7/6287639/10380310/10379079.pdf), [104](https://www.w3.org/news/2025/the-verifiable-credentials-2-0-family-of-specifications-is-now-a-w3c-recommendation/)].

| Policy & Consent Area | Core Challenge | Empirical Data Requirement | Desired Outcome |
| :--- | :--- | :--- | :--- |
| **Neurorights Enforcement** | Translating abstract legal rights into concrete, machine-enforceable rules. | Jurisdiction-specific legal frameworks for neurorights (e.g., Chile) and case law (e.g., Supreme Court rulings) [[6](https://www.linknovate.com/affiliation/columbia-university-210/all/?query=ultimately%20achieving%20unprecedented%20control), [107](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1330439/full)]. | Formalized, jurisdiction-aware delegation envelopes for the AI companion. |
| **Word-Math Band Tuning** | Defining objective criteria for prompt classifications (K/E/Y/Z/T/F/O) to minimize harm. | A large, labeled corpus of prompts rated by users on stigma, coercion, clarity, and usefulness . | An empirically tuned, data-driven policy for filtering and adapting prompts. |
| **Profile Portability (SSI Alignment)** | Ensuring the `AugmentedCitizenProfile` is interoperable and portable across different ecosystems. | Mapping tables from the custom profile schema to W3C VC standards and specific SSI ecosystems (e.g., IOTA) [[11](https://www.linkedin.com/posts/marcellus-nwankwo_w3c-did-verifiablecredentials-activity-7419046038809935872-Z2_T), [92](https://www.mdpi.com/1424-8220/22/15/5641)]. | A standardized, portable, and secure profile schema that respects user sovereignty. |

Ultimately, Phase 3 is about embedding ethics and law into the fabric of the technology. By grounding neurorights enforcement in legal precedent, tuning its governance mechanisms with user feedback, and building on open, decentralized identity standards, this phase ensures that the resulting system is not just innovative but also responsible and trustworthy. It transforms the AI companion from a simple utility into a guardian of user rights, operating transparently and in accordance with both technical best practices and societal values.

## System-Wide Architectural Framework and Implementation Strategy

The preceding phases of research are designed to validate and refine components of a larger, integrated architectural framework. This overarching model is built on the strategic insight that intelligence and complexity must reside primarily in the user's private, owned AI companion, while public terminals are simplified to stateless requestors of action. This separation of concerns is the cornerstone of a scalable, adaptable, and user-centric system. This final section synthesizes the research goals into a coherent architectural blueprint and outlines a pragmatic implementation strategy, addressing how a common interaction model can be generalized across diverse terminal types while accommodating their unique environmental constraints.

The core of the architecture is a shared interaction model that provides a universal grammar for all terminals, regardless of type or vendor . This model is built upon a set of shared primitives, including standard event types like `StartSession`, `SelectService`, `AuthorizePayment`, `IDCheck`, `NetworkDegraded`, `Abort`, and `Complete` . Complementing these events is a standardized set of `ConsentReason` codes, which explain why a particular action is being requested (e.g., `token invalid`, `network degraded`, `eco reward`, `neurorights alert`) . Finally, all terminals are expected to understand a minimal subset of the `AugmentedCitizenProfile`, specifically fields related to interaction mode, accessibility role, non-exclusion flags, and basic preferences like eco-rewards [[1](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)]. This shared vocabulary forms the foundation for interoperability. To implement this, a small, per-vendor adapter or normalization layer is deployed. This adapter sits between the terminal's proprietary backend and the AI companion's logic engine, translating vendor-specific nuances into the shared primitives . This modular approach allows the system to compute unified cross-terminal metrics (latency, completion rates) and train policies that generalize across pumps, pin-pads, and kiosks, while still respecting the unique operational realities of each device type .

The implementation strategy should follow a progressive upgrade path, recognizing that not all terminals can be upgraded simultaneously . The first, critical upgrade path is to bring all terminals to a shared minimum viable standard. This baseline requires support for the DID handshake for authentication, the ability to pass minimal accessibility flags, and basic mapping of `ConsentReason` codes . Achieving this common ground is essential for any meaningful cross-platform analysis and policy deployment. The second upgrade path involves progressively adding richer adaptive behaviors, guided by the data collected in the research phases. Based on the findings, environments showing the worst exclusion or failure rates—such as full-featured kiosks—should be prioritized for the most advanced upgrades. This includes implementing adaptive UI bundles that can reconfigure layout, contrast, and language in seconds, as well as integrating voice and touchless options [[1](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA), [2](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)]. In contrast, other environments, like in-store pin-pads, may require a different kind of upgrade. Here, the focus is on creating fast, seamless handoffs to the user's owned companion device (via NFC tap or QR code) to offload complexity, coupled with tightly constrained on-screen text patterns proven to be low-load and non-stigmatizing . Fuel pumps, due to their high-safety requirements, would demand the most conservative upgrades, focusing on robust offline modes for essential transactions and extremely fast fallbacks when the AI companion is unavailable .

A crucial aspect of the architecture is the clear differentiation of roles between the user's owned device and the public terminal . The owned device—the phone, headset, or implant—is the seat of intelligence and memory. It holds the full `AugmentedCitizenProfile`, the neurorights delegation envelopes, and a history of digital phenotyping data, all under the user's sovereign control [[14](https://www.researchgate.net/publication/373835915_Towards_Interoperable_Self-sovereign_Identities)]. This device is capable of performing rich real-time adaptation and long-term learning, as its storage and trust boundary are personal . In contrast, the public terminal (POS, pin-pad, kiosk) operates with a deliberately minimal view of the user. It only receives a small projection of the profile (e.g., `interaction_mode`, a few accessibility flags, and non-exclusion bits) along with a temporary session ID [[1](https://cdn.qwenlm.ai/qwen_url_parse_to_markdown/system00-0000-0000-0000-webUrlParser?key=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyZXNvdXJjZV91c2VyX2lkIjoicXdlbl91cmxfcGFyc2VfdG9fbWFya2Rvd24iLCJyZXNvdXJjZV9pZCI6InN5c3RlbTAwLTAwMDAtMDAwMC0wMDAwLXdlYlVybFBhcnNlciIsInJlc291cmNlX2NoYXRfaWQiOm51bGx9.cz1eeZEZdaQH5CgUaxwUmfEJfqTOZMoh3PbosHslSPA)]. The public terminal cannot store long-term per-user histories and must rely on the companion or a DID wallet for continuity. Any adaptation it performs must be slow, conservative, and derived from brief interaction tests or a one-time "profile hint" from the companion . This architectural dichotomy is fundamental to balancing flexibility with security and privacy. The research actions themselves should explicitly compare the outcomes of these two scenarios: 1) When the AI companion is present and provides hints, versus 2) When no companion is available and the terminal relies solely on its own limited public-side adaptation . Measuring the differences in cognitive load, trust, speed, and frequency of rights violations between these two conditions will provide direct evidence for the value of shifting intelligence to the user's side.

This phased research program, grounded in a clear architectural vision, offers a comprehensive pathway to realizing a more accessible and equitable future for public digital interactions. By systematically validating feasibility, assessing human impact, and refining governance, this program ensures that the resulting system is not only technologically sound but also deeply attuned to the needs and rights of its users.

| Component | Description | Key Characteristics | Rationale & Dependencies |
| :--- | :--- | :--- | :--- |
| **Shared Interaction Model** | A universal grammar of events, consent reasons, and minimal profile fields understood by all terminals. | Events: `StartSession`, `AuthorizePayment`. Reasons: `neurorights alert`, `network degraded`. Profile: `accessibility_role`, `non_exclusion_flag`. | Enables cross-vendor interoperability and unified policy management. Depends on defining a stable set of shared primitives.  |
| **Normalization Layer** | A per-vendor adapter that translates proprietary terminal messages into the shared interaction model. | Maps vendor-specific codes, data fields, and error messages to standardized primitives. | Makes the shared model practical for heterogeneous hardware (Verifone, Clover, SoftPOS). Requires detailed mapping tables from Phase 1.  |
| **AI Companion (Owned Device)** | Runs on user's personal device (phone, headset). Holds full profile, delegates rights, performs complex AI. | Full storage, long-term learning, rich real-time adaptation. Operates under user's sovereign control. | Centralizes intelligence and user control, minimizing complexity in public terminals. Performance depends on device resources (Phase 1).  |
| **Public Terminal (Projection)** | The POS, pin-pad, or kiosk. Receives only a minimal, temporary projection of user data. | Stateless, minimal data storage, conservative adaptation. Relies on companion or DID wallet for continuity. | Maximizes security and privacy by limiting the amount of persistent data on public hardware. Adaptation is constrained (Phase 2).  |
| **Upgrade Path** | A two-stage strategy for rolling out the system. | Stage 1: Baseline (DID handshake, minimal profile). Stage 2: Progressive enhancement (adaptive UI, richer handoffs). | Allows for gradual, manageable rollout. Prioritizes high-impact upgrades based on empirical data from Phases 2 & 3.  |